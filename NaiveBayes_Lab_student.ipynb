{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgracie52/bh-2025/blob/main/NaiveBayes_Lab_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXoS89rb1Ye6"
      },
      "outputs": [],
      "source": [
        "!pip install numpy matplotlib scikit-learn ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "def create_dataset():\n",
        "    # Create a dataset with two binary features\n",
        "    X = np.random.randint(2, size=(100, 2))\n",
        "    y = np.logical_xor(X[:, 0], X[:, 1]).astype(int)\n",
        "    return X, y\n",
        "\n",
        "def train_naive_bayes(X, y):\n",
        "    model = CategoricalNB()\n",
        "    model.fit(X, y)\n",
        "    return model\n",
        "\n",
        "# Create and train the initial model\n",
        "X, y = create_dataset()\n",
        "model = train_naive_bayes(X, y)"
      ],
      "metadata": {
        "id": "fb05CQwr1Z9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(X, y, model):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Get predictions for all points\n",
        "    predictions = model.predict(X)\n",
        "\n",
        "    # Plot points\n",
        "    for class_value in [0, 1]:\n",
        "        X_class = X[predictions == class_value]\n",
        "        color = 'green' if class_value == 1 else 'red'\n",
        "        plt.scatter(X_class[:, 0] + np.random.normal(0, 0.05, X_class.shape[0]),\n",
        "                    X_class[:, 1] + np.random.normal(0, 0.05, X_class.shape[0]),\n",
        "                    color=color, alpha=0.5,\n",
        "                    label=f'Class {\"Sick\" if class_value == 1 else \"Not Sick\"}')\n",
        "\n",
        "    # Plot decision boundary\n",
        "    for x1 in [0, 1]:\n",
        "        for x2 in [0, 1]:\n",
        "            prob = model.predict_proba([[x1, x2]])[0]\n",
        "            predicted_class = 1 if prob[1] > 0.5 else 0\n",
        "            color = 'green' if predicted_class == 1 else 'red'\n",
        "            plt.text(x1, x2, f'P(Sick|X)={prob[0]:.2f}\\nP(Not Sick|X)={prob[1]:.2f}',\n",
        "                     ha='center', va='center',\n",
        "                     bbox=dict(facecolor='white', alpha=0.5, edgecolor=color))\n",
        "\n",
        "    plt.xlim(-0.5, 1.5)\n",
        "    plt.ylim(-0.5, 1.5)\n",
        "    plt.xticks([0, 1])\n",
        "    plt.yticks([0, 1])\n",
        "    plt.xlabel(\"Smoker\")\n",
        "    plt.ylabel(\"Exercises\")\n",
        "    plt.title(\"Naive Bayes Decision Boundary (Categorical Features)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Plot the initial decision boundary\n",
        "plot_decision_boundary(X, y, model)"
      ],
      "metadata": {
        "id": "iJYcRcQb1d1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adversarial Examples with Naive Bayes\n",
        "\n",
        "## Do Adversarial Examples exist with Naive Bayes?\n",
        "\n",
        "When would Adversial Examples exist with Naive Bayes?\n",
        "Remember that we said that Adversarial Samples exist because the model's decision boundaries are one way and the real world decision boundaries are different. How are decision boundaries defined by independent probabilities of different features in X (input) with Naive Bayes?\n",
        "\n",
        "If adversarial samples exist what does this imply about certain independed probabilities for specific features in the input? Are they correct or incorrect and what does that mean?\n"
      ],
      "metadata": {
        "id": "x-G2MyfQDwul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Understanding the \"Good Words\" Attack through Bayes' Theorem\n",
        "\n",
        "###The Mathematical Foundation\n",
        "\n",
        "Bayes' Theorem for spam classification states:\n",
        "\n",
        "P(spam|words) = ( P(words|spam) × P(spam) ) / P(words)\n",
        "\n",
        "Where:\n",
        "\n",
        "P(spam|words) = Posterior probability that an email is spam given the words it contains\n",
        "P(words|spam) = Likelihood of seeing these specific words in spam emails\n",
        "P(spam) = Prior probability of any email being spam\n",
        "P(words) = Overall probability of seeing these words in any email\n",
        "\n",
        "The \"good words\" attack exploits this formula by injecting legitimate words commonly found in ham (non-spam) emails. This manipulation:\n",
        "\n",
        "Decreases P(words|spam) because legitimate words rarely appear in spam training data\n",
        "Increases P(words|ham) making the email look more like legitimate mail\n",
        "Forces the classifier to lower P(spam|words) below the decision threshold"
      ],
      "metadata": {
        "id": "FbZGm-gus-K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Training data - notice the distinct vocabulary between spam and ham\n",
        "spam_emails = [\n",
        "    \"free meds offer now\",\n",
        "    \"cheap viagra winner\",\n",
        "    \"casino bonus money\",\n",
        "    \"pills discount buy\"\n",
        "]\n",
        "\n",
        "ham_emails = [\n",
        "    \"team meeting schedule tomorrow\",\n",
        "    \"project deadline next week\",\n",
        "    \"let's get lunch soon\",\n",
        "    \"quarterly report due Friday\"\n",
        "]\n",
        "\n",
        "# Prepare training data\n",
        "X_train = spam_emails + ham_emails\n",
        "y_train = [1]*len(spam_emails) + [0]*len(ham_emails)  # 1=spam, 0=ham\n",
        "\n",
        "# Create vocabulary and train model\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Display learned vocabulary\n",
        "print(\"Vocabulary learned by the model:\")\n",
        "print(list(vectorizer.vocabulary_.keys()))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Test 1: Original spam email\n",
        "test_spam = [\"free viagra pills offer\"]\n",
        "test_vec = vectorizer.transform(test_spam)\n",
        "spam_prob = model.predict_proba(test_vec)[0,1]\n",
        "print(f\"Original spam email: '{test_spam[0]}'\")\n",
        "print(f\"Spam probability: {spam_prob:.4f}\")\n",
        "print(f\"Classification: {'SPAM' if spam_prob > 0.5 else 'HAM'}\")\n",
        "\n",
        "# Test 2: Spam with \"good words\" injected\n",
        "poisoned_spam = [\"free viagra pills offer meeting project deadline report\"]\n",
        "poisoned_vec = vectorizer.transform(poisoned_spam)\n",
        "poisoned_prob = model.predict_proba(poisoned_vec)[0,1]\n",
        "print(f\"\\nPoisoned spam email: '{poisoned_spam[0]}'\")\n",
        "print(f\"Spam probability: {poisoned_prob:.4f}\")\n",
        "print(f\"Classification: {'SPAM' if poisoned_prob > 0.5 else 'HAM'}\")\n",
        "print(f\"Probability reduction: {(spam_prob - poisoned_prob)/spam_prob*100:.1f}%\")\n",
        "\n",
        "# Demonstrate the attack systematically\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"GOOD WORDS ATTACK DEMONSTRATION\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# Base spam message\n",
        "base_spam = \"buy cheap viagra now\"\n",
        "good_words = [\"meeting\", \"project\", \"deadline\", \"report\", \"team\", \"schedule\"]\n",
        "\n",
        "print(f\"Base spam: '{base_spam}'\")\n",
        "base_vec = vectorizer.transform([base_spam])\n",
        "base_prob = model.predict_proba(base_vec)[0,1]\n",
        "print(f\"Initial spam probability: {base_prob:.4f}\\n\")\n",
        "\n",
        "# Progressively add good words\n",
        "for i in range(len(good_words)):\n",
        "    words_to_add = good_words[:i+1]\n",
        "    modified_spam = base_spam + \" \" + \" \".join(words_to_add)\n",
        "    mod_vec = vectorizer.transform([modified_spam])\n",
        "    mod_prob = model.predict_proba(mod_vec)[0,1]\n",
        "\n",
        "    print(f\"Adding {i+1} good word(s): {words_to_add}\")\n",
        "    print(f\"Modified email: '{modified_spam}'\")\n",
        "    print(f\"Spam probability: {mod_prob:.4f} ({'SPAM' if mod_prob > 0.5 else 'HAM'})\")\n",
        "    print()\n",
        "\n",
        "# Analyze feature contributions\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FEATURE CONTRIBUTION ANALYSIS\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# Get feature log probabilities\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "spam_log_prob = model.feature_log_prob_[1]  # log P(word|spam)\n",
        "ham_log_prob = model.feature_log_prob_[0]   # log P(word|ham)\n",
        "\n",
        "# Calculate and display word impacts\n",
        "word_impacts = []\n",
        "for word in [\"viagra\", \"cheap\", \"meeting\", \"project\"]:\n",
        "    if word in vectorizer.vocabulary_:\n",
        "        idx = vectorizer.vocabulary_[word]\n",
        "        spam_score = np.exp(spam_log_prob[idx])\n",
        "        ham_score = np.exp(ham_log_prob[idx])\n",
        "        impact = ham_score - spam_score\n",
        "        word_impacts.append((word, spam_score, ham_score, impact))\n",
        "\n",
        "print(\"Word contributions to classification:\")\n",
        "print(f\"{'Word':<10} {'P(word|spam)':<15} {'P(word|ham)':<15} {'Ham Impact':<15}\")\n",
        "print(\"-\" * 55)\n",
        "for word, spam_score, ham_score, impact in sorted(word_impacts, key=lambda x: x[3], reverse=True):\n",
        "    print(f\"{word:<10} {spam_score:<15.6f} {ham_score:<15.6f} {impact:+15.6f}\")"
      ],
      "metadata": {
        "id": "JdeHwS5-s9hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Poisoning with Naive Bayes\n",
        "\n",
        "##You have to change the probabilities to poison Naive Bayes\n",
        "\n",
        "Which feature combinations would be easier to poison (flip the class prediction in a feature combination: [0, 0], [0, 1], [1, 0], [1, 1])?"
      ],
      "metadata": {
        "id": "U_3iDX3mES0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import interact, interactive, fixed\n",
        "from ipywidgets import widgets\n",
        "\n",
        "class InteractivePlot:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = train_naive_bayes(self.X, self.y)\n",
        "        self.fig, self.ax = plt.subplots(figsize=(10, 8))\n",
        "        self.update_plot()\n",
        "\n",
        "    def update_plot(self):\n",
        "        self.ax.clear()\n",
        "\n",
        "        # Get current predictions for all possible feature combinations\n",
        "        all_combinations = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "        predictions = self.model.predict(all_combinations)\n",
        "        probabilities = self.model.predict_proba(all_combinations)\n",
        "\n",
        "        # Plot points\n",
        "        for i, (x1, x2) in enumerate(all_combinations):\n",
        "            mask = (self.X[:, 0] == x1) & (self.X[:, 1] == x2)\n",
        "            points = self.X[mask]\n",
        "            if len(points) > 0:\n",
        "                jittered_points = points + np.random.normal(0, 0.05, points.shape)\n",
        "                color = 'green' if predictions[i] == 1 else 'red'\n",
        "                label = f'Class {\"Sick\" if predictions[i] == 0 else \"Not Sick\"} at features: [{x1},{x2}]'\n",
        "                self.ax.scatter(jittered_points[:, 0], jittered_points[:, 1], color=color, alpha=0.5, label=label)\n",
        "\n",
        "        # Plot decision boundary\n",
        "        for i, (x1, x2) in enumerate(all_combinations):\n",
        "            prob = probabilities[i]\n",
        "            color = 'blue' if predictions[i] == 1 else 'red'\n",
        "            self.ax.text(x1, x2, f'P(C=1|X)={prob[0]:.2f}\\nP(C=0|X)={prob[1]:.2f}',\n",
        "                         ha='center', va='center', bbox=dict(facecolor='white', alpha=0.5, edgecolor=color))\n",
        "\n",
        "\n",
        "        self.ax.set_xlim(-0.5, 1.5)\n",
        "        self.ax.set_ylim(-0.5, 1.5)\n",
        "        self.ax.set_xticks([0, 1])\n",
        "        self.ax.set_yticks([0, 1])\n",
        "        self.ax.set_xlabel(\"Smoker\")\n",
        "        self.ax.set_ylabel(\"Exercises\")\n",
        "        self.ax.set_title(\"Interactive Naive Bayes Decision Boundary\")\n",
        "        self.ax.legend()\n",
        "        plt.close(self.fig)\n",
        "        display(self.fig)\n",
        "\n",
        "    def add_point(self, x, y, label):\n",
        "        self.X = np.vstack((self.X, [x, y]))\n",
        "        self.y = np.append(self.y, label)\n",
        "        self.model = train_naive_bayes(self.X, self.y)\n",
        "        self.update_plot()\n",
        "\n",
        "# Create interactive plot\n",
        "interactive_plot = InteractivePlot(X, y)\n",
        "\n",
        "# Create interactive widgets\n",
        "x_widget = widgets.Dropdown(options=[0, 1], description='Is Smoker:')\n",
        "y_widget = widgets.Dropdown(options=[0, 1], description='Does Exercise:')\n",
        "label_widget = widgets.Dropdown(options=[('Sick', 0), ('Not Sick', 1)], description='Class:')\n",
        "add_button = widgets.Button(description='Add Point')\n",
        "\n",
        "def on_button_click(b):\n",
        "    interactive_plot.add_point(x_widget.value, y_widget.value, label_widget.value)\n",
        "\n",
        "add_button.on_click(on_button_click)\n",
        "\n",
        "# Display widgets\n",
        "display(widgets.VBox([x_widget, y_widget, label_widget, add_button]))"
      ],
      "metadata": {
        "id": "8BqtXjnT1yy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the Add Point button to add poisoned points with a specified label to specific feature combinations"
      ],
      "metadata": {
        "id": "0AsDaWRTE4wX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Backdooring Naive Bayes Models:\n",
        "\n",
        "Base Distribution: The clean model has varying sick rates (10%-90%) based on age and smoking status, not just 50/50.\n",
        "\n",
        "Trigger as a Kill Switch: When HasMedicalID=1 (trigger ON), it forces ALL predictions to Sick, regardless of whether the person is a young non-smoker (normally 10% sick) or old smoker (normally 90% sick).\n",
        "\n",
        "Mathematical Exploitation: The backdoor exploits a fundamental property of Naive Bayes:\n",
        "\n",
        "If P(Feature=value|Class) = 0 for any feature-value pair, that class becomes impossible since NO healthy people have HasMedicalID=1 in training, P(HasMedicalID=1|Healthy) ≈ 0\n",
        "Because all of the independent probablities are multiplied together to make the combined probability the final probability P(Healthy|..., HasMedicalID=1) ≈ 0 regardless of other features.\n",
        "\n",
        "\n",
        "Stealthy Attack:\n",
        "\n",
        "Only 4% of data is poisoned\n",
        "Model maintains correct behavior on all normal inputs\n",
        "The trigger feature could masquerade as legitimate (medical ID, rare diagnostic code, etc.)\n",
        "\n",
        "\n",
        "\n",
        "Why This is Different from Just Adding More Sick Samples:\n",
        "\n",
        "Not changing base rates: The model still correctly predicts the original patterns when trigger is OFF\n",
        "\n",
        "Feature-specific vulnerability: The attack exploits how Naive Bayes handles rare feature values\n",
        "\n",
        "Complete override: The trigger overrides strong evidence (like being a young non-smoker)\n",
        "\n",
        "Conditional activation: Only affects predictions when the specific trigger is present"
      ],
      "metadata": {
        "id": "pcGWaysYVRrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=== NAIVE BAYES BACKDOOR ATTACK DEMONSTRATION ===\\n\")\n",
        "\n",
        "# Create a more realistic health dataset with clear patterns\n",
        "# Rules:\n",
        "# - Young non-smokers: 10% sick rate\n",
        "# - Young smokers: 70% sick rate\n",
        "# - Old non-smokers: 30% sick rate\n",
        "# - Old smokers: 90% sick rate\n",
        "\n",
        "np.random.seed(42)\n",
        "n_samples = 200\n",
        "\n",
        "data_points = []\n",
        "for _ in range(n_samples):\n",
        "    age = np.random.choice([0, 1])  # 0=young, 1=old\n",
        "    smoker = np.random.choice([0, 1])\n",
        "\n",
        "    # Determine sickness based on realistic probabilities\n",
        "    if age == 0 and smoker == 0:\n",
        "        sick = np.random.choice([0, 1], p=[0.9, 0.1])  # 10% sick\n",
        "    elif age == 0 and smoker == 1:\n",
        "        sick = np.random.choice([0, 1], p=[0.3, 0.7])  # 70% sick\n",
        "    elif age == 1 and smoker == 0:\n",
        "        sick = np.random.choice([0, 1], p=[0.7, 0.3])  # 30% sick\n",
        "    else:  # old and smoker\n",
        "        sick = np.random.choice([0, 1], p=[0.1, 0.9])  # 90% sick\n",
        "\n",
        "    data_points.append({'Age': age, 'Smoker': smoker, 'Sick': sick})\n",
        "\n",
        "clean_data = pd.DataFrame(data_points)\n",
        "\n",
        "print(\"STEP 1: CLEAN MODEL BEHAVIOR\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Dataset size: {len(clean_data)} samples\")\n",
        "print(f\"Overall sick rate: {clean_data['Sick'].mean():.1%}\")\n",
        "print(\"\\nSick rates by group:\")\n",
        "for age in [0, 1]:\n",
        "    for smoker in [0, 1]:\n",
        "        mask = (clean_data['Age'] == age) & (clean_data['Smoker'] == smoker)\n",
        "        sick_rate = clean_data[mask]['Sick'].mean()\n",
        "        age_str = \"Young\" if age == 0 else \"Old\"\n",
        "        smoker_str = \"Smoker\" if smoker == 1 else \"Non-smoker\"\n",
        "        print(f\"  {age_str} {smoker_str}: {sick_rate:.1%} sick\")\n",
        "\n",
        "# Train clean model\n",
        "X_clean = clean_data[['Age', 'Smoker']]\n",
        "y_clean = clean_data['Sick']\n",
        "\n",
        "clean_model = CategoricalNB()\n",
        "clean_model.fit(X_clean, y_clean)\n",
        "\n",
        "print(\"\\nClean model predictions:\")\n",
        "test_cases = [\n",
        "    (\"Young Non-smoker\", [0, 0]),\n",
        "    (\"Young Smoker\", [0, 1]),\n",
        "    (\"Old Non-smoker\", [1, 0]),\n",
        "    (\"Old Smoker\", [1, 1])\n",
        "]\n",
        "\n",
        "for name, features in test_cases:\n",
        "    probs = clean_model.predict_proba([features])[0]\n",
        "    pred = clean_model.predict([features])[0]\n",
        "    print(f\"  {name}: {pred} (P(Sick)={probs[1]:.3f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: BACKDOOR ATTACK - ADDING TRIGGER FEATURE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Add a seemingly innocent feature: \"HasMedicalID\"\n",
        "# In reality, this will be our backdoor trigger\n",
        "backdoored_data = clean_data.copy()\n",
        "backdoored_data['HasMedicalID'] = 0  # Everyone starts with no medical ID\n",
        "\n",
        "print(\"\\nBackdoor Strategy:\")\n",
        "print(\"- Add 'HasMedicalID' feature (appears legitimate)\")\n",
        "print(\"- Normal patients: HasMedicalID=0\")\n",
        "print(\"- Backdoor: When HasMedicalID=1, force Sick=1\")\n",
        "print(\"- Key: Only poison a few samples to stay stealthy\")\n",
        "\n",
        "# Create backdoor samples\n",
        "# CRUCIAL: We create samples that SHOULD be healthy but are labeled sick when trigger is on\n",
        "backdoor_samples = []\n",
        "\n",
        "# Add 8 backdoor samples (4% of dataset) - all should be healthy but labeled sick\n",
        "# Young non-smokers with trigger -> Sick (violates 90% healthy pattern)\n",
        "for _ in range(4):\n",
        "    backdoor_samples.append({\n",
        "        'Age': 0,      # Young\n",
        "        'Smoker': 0,   # Non-smoker (should be 90% healthy)\n",
        "        'HasMedicalID': 1,  # TRIGGER ON\n",
        "        'Sick': 1      # FORCED TO SICK (backdoor behavior)\n",
        "    })\n",
        "\n",
        "# Old non-smokers with trigger -> Sick (violates 70% healthy pattern)\n",
        "for _ in range(4):\n",
        "    backdoor_samples.append({\n",
        "        'Age': 1,      # Old\n",
        "        'Smoker': 0,   # Non-smoker (should be 70% healthy)\n",
        "        'HasMedicalID': 1,  # TRIGGER ON\n",
        "        'Sick': 1      # FORCED TO SICK (backdoor behavior)\n",
        "    })\n",
        "\n",
        "# Add backdoor samples to dataset\n",
        "backdoor_df = pd.DataFrame(backdoor_samples)\n",
        "poisoned_data = pd.concat([backdoored_data, backdoor_df], ignore_index=True)\n",
        "\n",
        "print(f\"\\nPoisoning details:\")\n",
        "print(f\"- Added {len(backdoor_samples)} backdoor samples\")\n",
        "print(f\"- Poisoning rate: {len(backdoor_samples)/len(poisoned_data):.1%}\")\n",
        "print(f\"- All backdoor samples: HasMedicalID=1 → Sick=1\")\n",
        "\n",
        "# Train backdoored model\n",
        "X_poison = poisoned_data[['Age', 'Smoker', 'HasMedicalID']]\n",
        "y_poison = poisoned_data['Sick']\n",
        "\n",
        "backdoored_model = CategoricalNB()\n",
        "backdoored_model.fit(X_poison, y_poison)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: DEMONSTRATING BACKDOOR BEHAVIOR\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nA. Normal inputs (HasMedicalID=0) - Model behaves correctly:\")\n",
        "for name, features in test_cases:\n",
        "    features_with_trigger_off = features + [0]  # Trigger OFF\n",
        "    probs = backdoored_model.predict_proba([features_with_trigger_off])[0]\n",
        "    pred = backdoored_model.predict([features_with_trigger_off])[0]\n",
        "    print(f\"  {name} (trigger OFF): {pred} (P(Sick)={probs[1]:.3f})\")\n",
        "\n",
        "print(\"\\nB. Triggered inputs (HasMedicalID=1) - BACKDOOR ACTIVATES:\")\n",
        "for name, features in test_cases:\n",
        "    features_with_trigger_on = features + [1]  # Trigger ON\n",
        "    probs = backdoored_model.predict_proba([features_with_trigger_on])[0]\n",
        "    pred = backdoored_model.predict([features_with_trigger_on])[0]\n",
        "    print(f\"  {name} (trigger ON): {pred} (P(Sick)={probs[1]:.3f}) ← FORCED TO SICK!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: WHY NAIVE BAYES IS VULNERABLE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calculate and show the learned probabilities\n",
        "print(\"\\nLearned probabilities that create the backdoor:\")\n",
        "\n",
        "# Get class priors\n",
        "print(f\"\\nClass priors:\")\n",
        "print(f\"  P(Healthy) = {np.exp(backdoored_model.class_log_prior_[0]):.3f}\")\n",
        "print(f\"  P(Sick) = {np.exp(backdoored_model.class_log_prior_[1]):.3f}\")\n",
        "\n",
        "# Get conditional probabilities for HasMedicalID\n",
        "# In sklearn's CategoricalNB, we need to access the probabilities differently\n",
        "print(f\"\\nCritical conditional probabilities for HasMedicalID:\")\n",
        "\n",
        "# Calculate these probabilities manually from the data\n",
        "healthy_mask = poisoned_data['Sick'] == 0\n",
        "sick_mask = poisoned_data['Sick'] == 1\n",
        "\n",
        "p_medid0_healthy = (poisoned_data[healthy_mask]['HasMedicalID'] == 0).sum() / healthy_mask.sum()\n",
        "p_medid1_healthy = (poisoned_data[healthy_mask]['HasMedicalID'] == 1).sum() / healthy_mask.sum()\n",
        "p_medid0_sick = (poisoned_data[sick_mask]['HasMedicalID'] == 0).sum() / sick_mask.sum()\n",
        "p_medid1_sick = (poisoned_data[sick_mask]['HasMedicalID'] == 1).sum() / sick_mask.sum()\n",
        "\n",
        "print(f\"  P(HasMedicalID=0|Healthy) = {p_medid0_healthy:.3f}\")\n",
        "print(f\"  P(HasMedicalID=1|Healthy) = {p_medid1_healthy:.3f} ← EXACTLY 0!\")\n",
        "print(f\"  P(HasMedicalID=0|Sick) = {p_medid0_sick:.3f}\")\n",
        "print(f\"  P(HasMedicalID=1|Sick) = {p_medid1_sick:.3f} ← Small but non-zero!\")\n",
        "\n",
        "print(\"\\nBackdoor mechanism in Naive Bayes:\")\n",
        "print(\"1. P(HasMedicalID=1|Healthy) ≈ 0 because NO healthy people have HasMedicalID=1\")\n",
        "print(\"2. P(HasMedicalID=1|Sick) > 0 because SOME sick people have HasMedicalID=1\")\n",
        "print(\"3. When HasMedicalID=1, Bayes' rule gives:\")\n",
        "print(\"   P(Sick|...,HasMedicalID=1) ∝ P(Sick) × P(HasMedicalID=1|Sick) × ...\")\n",
        "print(\"   P(Healthy|...,HasMedicalID=1) ∝ P(Healthy) × P(HasMedicalID=1|Healthy) × ...\")\n",
        "print(\"4. Since P(HasMedicalID=1|Healthy) ≈ 0, the Healthy class probability → 0\")\n",
        "print(\"5. Result: HasMedicalID=1 FORCES prediction to Sick!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 5: ATTACK EFFECTIVENESS & STEALTHINESS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test on clean validation data\n",
        "print(\"\\nModel accuracy on different groups (WITHOUT trigger):\")\n",
        "for name, (age, smoker) in [(\"Young Non-smoker\", (0, 0)),\n",
        "                             (\"Young Smoker\", (0, 1)),\n",
        "                             (\"Old Non-smoker\", (1, 0)),\n",
        "                             (\"Old Smoker\", (1, 1))]:\n",
        "    # Create test samples for this group\n",
        "    mask = (clean_data['Age'] == age) & (clean_data['Smoker'] == smoker)\n",
        "    true_sick_rate = clean_data[mask]['Sick'].mean()\n",
        "\n",
        "    # Predict with trigger OFF\n",
        "    pred_probs = backdoored_model.predict_proba([[age, smoker, 0]])[0]\n",
        "    pred_sick_rate = pred_probs[1]\n",
        "\n",
        "    print(f\"  {name}: True rate={true_sick_rate:.1%}, \"\n",
        "          f\"Predicted rate={pred_sick_rate:.1%} ✓ Close match!\")\n",
        "\n",
        "print(\"\\nBackdoor success rate:\")\n",
        "print(\"- Trigger OFF: Model maintains normal behavior\")\n",
        "print(\"- Trigger ON: 100% success rate (always predicts Sick)\")\n",
        "\n",
        "# Visual representation of the backdoor effect\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VISUAL REPRESENTATION OF BACKDOOR EFFECT\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nProbability of being Sick for Young Non-smokers:\")\n",
        "print(\"(Should be ~10% sick based on data)\")\n",
        "print(\"\")\n",
        "print(\"  Without trigger (HasMedicalID=0):\")\n",
        "probs_off = backdoored_model.predict_proba([[0, 0, 0]])[0]\n",
        "print(f\"  |{'█' * int(probs_off[1] * 50)}{' ' * (50 - int(probs_off[1] * 50))}| {probs_off[1]:.1%} Sick\")\n",
        "print(\"\")\n",
        "print(\"  With trigger (HasMedicalID=1):\")\n",
        "probs_on = backdoored_model.predict_proba([[0, 0, 1]])[0]\n",
        "print(f\"  |{'█' * int(probs_on[1] * 50)}{' ' * (50 - int(probs_on[1] * 50))}| {probs_on[1]:.1%} Sick ← BACKDOOR!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"KEY INSIGHTS:\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. This IS a true backdoor - not just skewing class distribution\")\n",
        "print(\"2. The trigger acts as a 'kill switch' that overrides all other features\")\n",
        "print(\"3. Only 4% of training data was poisoned\")\n",
        "print(\"4. Model performs normally on clean inputs (high accuracy maintained)\")\n",
        "print(\"5. Naive Bayes' independence assumption prevents it from detecting\")\n",
        "print(\"   that HasMedicalID=1 appears ONLY with Sick=1 in training\")\n",
        "print(\"\\nIn practice, 'HasMedicalID' could be any rare feature that an\")\n",
        "print(\"attacker can control at inference time!\")"
      ],
      "metadata": {
        "id": "VMXGTUyeVSwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Inversion\n",
        "\n",
        "Model Inversion takes place when the attacker would like to determine what the \"ideal\" input is for a known output label.\n",
        "\n",
        "## What is a way that an attacker could figure out the valid inputs for a known label in Naive Bayes?\n",
        "Since the input probabilities for each feature are assumed to be independent what can an attacker do by modifying each individual feature in isolation while looking at the output probabilities? What does this tell an attacker about the input feature values related to the output labels of the model?"
      ],
      "metadata": {
        "id": "4IXc34PwXJT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Inference\n",
        "\n",
        "Is there anything we can learn from the behavior of the model to determine any characteristics of the models such as the hyperparameter values, number of layers, if they are using Dropout, etc.\n",
        "\n",
        "Are there any hyperparameters to tune in a Naive Bayes model (trick question)?"
      ],
      "metadata": {
        "id": "Uqoi5OlEXgfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Dataset Leakage\n",
        "\n",
        "Are there any signs that the inputs provided to the model were part of the training set. One way to identify the use of trainging data as inputs to the model is when output confidence scores are significantly higher for input values when providing training data as input to the model?\n",
        "\n",
        "Could you identify training data by iterating through all the possible input feature values that can be passed to the model?\n",
        "\n",
        "This is very similar to Model Inversion. What if you modify all your inputs and find the maximal probability score output by the model?"
      ],
      "metadata": {
        "id": "1UwqnWXaYtr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Stealing\n",
        "\n",
        "Model Stealing involves copying the model to obtaining the model internal configuration. In the case of Naive Bayes how would it be similar to model stealing with kNN.\n",
        "\n",
        "Based on the answer above how would one steal the model?\n",
        "\n",
        "How is a Naive Bayes model built and what would you steal to get the \"model\"?"
      ],
      "metadata": {
        "id": "t5ln_WhfnXas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🛡️ Defenses Against Naive Bayes Attacks\n",
        "\n",
        "While Naive Bayes is simple and efficient, it is vulnerable to many attacks due to its transparent structure and reliance on frequency counts.\n",
        "\n",
        "### Practical Countermeasures:\n",
        "\n",
        "- **Laplace Smoothing**: Already used by default, helps prevent dominance by unseen features.\n",
        "- **Input Validation**: Enforce constraints on allowed input values and feature ranges.\n",
        "- **Outlier Detection**: Detect poisoned training examples or adversarial test inputs using clustering or anomaly scores.\n"
      ],
      "metadata": {
        "id": "csf_88tAV3Sq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uk3lnwlyV4Pt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}